# COVID Data Engineering Project

## Overview
This project is designed to handle the end-to-end data engineering pipeline for COVID-19 data. It includes data fetching, transformation, and loading into analytics databases. The project leverages tools like Apache Airflow, dbt (Data Build Tool), and Snowflake for efficient data processing and management.

## Project Structure

- **airflow_settings.yaml**: Configuration for Apache Airflow.
- **app.py**: Main application script.
- **docker-compose.yml**: Docker Compose file for setting up the environment.
- **Dockerfile**: Docker configuration for containerizing the application.
- **requirements.txt**: Python dependencies for the project.
- **settings.py**: Project-specific settings.
- **artifacts/**: Contains intermediate and final data artifacts.
  - **DataFetchArtifacts/**: Raw data files.
  - **DataTransformationArtifacts/**: Transformed data files.
- **config/**: Configuration files for Airflow and other tools.
- **covid_data_transformation/**: dbt project for transforming COVID-19 data.
  - **models/**: SQL scripts for data modeling.
  - **logs/**: Logs generated by dbt.
  - **target/**: Compiled and run results from dbt.
- **dags/**: Airflow DAGs for orchestrating workflows.
- **database/**: Database configuration files.
- **src/**: Source code for various components.
  - **components/**: Scripts for data fetching, loading, and transformation.
  - **constant/**: Constants used across the project.
  - **entity/**: Entity definitions and configurations.
  - **exception/**: Custom exception handling.
  - **logger/**: Logging utilities.
  - **pipeline/**: Pipeline scripts, including inference pipelines.
  - **utils.py/**: Common utility functions.
- **tests/**: Test cases for validating the functionality of DAGs and other components.

## Key Features

1. **Data Fetching**: Scripts to fetch raw COVID-19 data from external sources.
2. **Data Transformation**: dbt models to clean and transform the data.
3. **Data Loading**: Load transformed data into Snowflake for analytics.
4. **Workflow Orchestration**: Apache Airflow DAGs to automate the entire pipeline.
5. **Logging and Monitoring**: Comprehensive logging for debugging and monitoring.

## Prerequisites

- Docker and Docker Compose
- Python 3.8+
- Apache Airflow
- dbt
- Snowflake account (for data storage)

## Setup Instructions

1. Clone the repository:
   ```bash
   git clone <repository-url>
   cd covid_data_engineering_project
   ```

2. Build and start the Docker containers:
   ```bash
   docker-compose up --build
   ```

3. Install Python dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. Configure Airflow:
   - Update `airflow_settings.yaml` and `airflow.cfg` as needed.

5. Configure dbt:
   - Update `dbt_project.yml` and `profiles.yml` with your database credentials.

6. Run the Airflow webserver and scheduler:
   ```bash
   airflow webserver &
   airflow scheduler
   ```

7. Trigger the DAGs from the Airflow UI.

## Usage

- **Data Fetching**: Run the `data_fetching.py` script to fetch raw data.
- **Data Transformation**: Use dbt to transform the data:
  ```bash
  dbt run
  ```
- **Data Loading**: Execute the `load_data_snowflake.py` script to load data into Snowflake.

## Testing

Run the test cases using:
```bash
pytest
```

## Contributing

Contributions are welcome! Please follow the standard Git workflow:
1. Fork the repository.
2. Create a new branch for your feature/bugfix.
3. Commit your changes and push to your fork.
4. Submit a pull request.

## License

This project is licensed under the MIT License. See the `LICENSE` file for details.

## Acknowledgments

- Apache Airflow for workflow orchestration.
- dbt for data transformation.
- Snowflake for data storage and analytics.

## Additional Resources

- **documents_photos/**: Contains reference documents and photos related to the project.
    - **design_docs/**: Design documentation for the pipeline.
    - **visualizations/**: Graphs and charts for data insights.
    - **Airflow/**: Screenshots of the Airflow UI and dbt runs.

## ScreenShots

![Airflow](documents_photos\Airflow.png)
![Snowflake Database](D:\vscode\covid_data_engineering_project\documents_photos\Snowflake_Database.png)
